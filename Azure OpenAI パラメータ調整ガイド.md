# Azure OpenAI パラメータ調整ガイド

## 概要

Azure OpenAIやOpenAI APIでは、**temperature**や**top_p**などのパラメーター調整によって、  
生成されるテキストやコードの**品質・多様性・正確性**をコントロールできます。  
このドキュメントでは、数値系パラメーターに絞り、**ハルシネーション（事実誤り）対策や使いやすさ向上、コーディング用途でのベストプラクティス**を解説します。

---

## 1. 数値系パラメーター一覧

| パラメーター名         | 型      | 説明                                                         |
|---------------------|--------|------------------------------------------------------------|
| `temperature`       | float  | 応答のランダム性・多様性。0に近いほど決定論的、1以上で発散的。          |
| `top_p`             | float  | nucleus sampling の割合（確率質量上位p%から選択）。                   |
| `max_tokens`        | int    | 生成される最大トークン数。                                     |
| `frequency_penalty` | float  | 同語句・同内容の繰り返し抑制。                                 |
| `presence_penalty`  | float  | 新規話題・未出単語を促進/抑制。                                |

---

## 2. 各パラメーターの調整方針とその効果

### temperature
- **説明**: 低いほど定型的・安定した出力、高いほど多様性（ランダム性）が上昇。
- **推奨設定**:  
  - 事実重視やコード生成→**0.0〜0.2**
  - クリエイティブ用途→**0.7〜1.0**

### top_p
- **説明**: サンプリング候補を高確率な単語だけに絞る。
- **推奨設定**:  
  - 厳密系→**0.7〜0.9**
  - 多様性重視→**0.95〜1.0**

### max_tokens
- **説明**: 応答文の長さ上限。短すぎると途中で切れる、長すぎると脱線リスク増。
- **推奨設定**:  
  - 必要量＋10〜20％ほど余裕を持たせる

### frequency_penalty
- **説明**: 繰り返しを減らすペナルティ。0以上で冗長さを抑制。
- **推奨設定**:  
  - コードや文書→**0.1〜0.3**
  - 文章の自然さ維持重視なら0付近

### presence_penalty
- **説明**: 新しい話題を持ち込みやすくするペナルティ。高いと話題が分散しやすい。
- **推奨設定**:  
  - 事実系やコード→**0または-0.1**
  - 発想拡張したい時のみ高めに（0.5など）

---

## 3. ハルシネーションや間違いを抑えるための推奨値

- **基本は低温・低多様性**
    - `temperature`: **0.0〜0.2**
    - `top_p`: **0.7〜0.9**
    - `max_tokens`: **必要最小限＋少し余裕**
    - `frequency_penalty`: **0.1〜0.3**
    - `presence_penalty`: **0〜-0.1**
- **注意**  
    - 温度もtop_pも両方高くしすぎない（どちらか片方を調整）。
    - 温度0でも誤りが「ゼロ」にはならない点に注意。

---

## 4. 用途別プリセット例

### 厳密なQ&Aやコード生成
| パラメーター         | 推奨値例         |
|---------------------|-----------------|
| temperature         | 0.05〜0.2       |
| top_p               | 0.75〜0.9       |
| max_tokens          | 256〜2048（必要量） |
| frequency_penalty   | 0.1〜0.2        |
| presence_penalty    | 0〜-0.1         |

### 要約や事実確認重視
| パラメーター         | 推奨値例         |
|---------------------|-----------------|
| temperature         | 0.2〜0.3        |
| top_p               | 0.8〜0.9        |
| frequency_penalty   | 0.2             |
| presence_penalty    | 0               |

### クリエイティブ・アイデア出し
| パラメーター         | 推奨値例         |
|---------------------|-----------------|
| temperature         | 0.7〜1.0        |
| top_p               | 0.95〜1.0       |
| frequency_penalty   | 0.1〜0.3        |
| presence_penalty    | 0.3〜0.6        |

---

## 5. コーディング用途での推奨設定

- **temperature**: 0.05〜0.2（できるだけ低く固定することで安定性アップ）
- **top_p**: 0.75〜0.9（rare token混入を防ぐ）
- **max_tokens**: 必要なコード長＋説明文をカバーできる量
- **frequency_penalty**: 0.1〜0.2（ループやimportの重複を予防）
- **presence_penalty**: 0または-0.1（話題のぶれを抑制）

**ポイント**
- 温度0.1 & top_p 0.8など「低温×絞り込み」で、構文エラーやハルシネーションを大幅に減らせる
- それでも複数生成→自動テストで正答を選ぶのがベストプラクティス

---

## 6. ハルシネーション低減の追加Tips

- 温度・top_pはどちらか片方だけを動かす（両方上げると誤答が激増）
- max_tokensは余裕を持たせつつ必要最小限で
- frequency_penalty/presence_penaltyを適度に付与して冗長化や脱線を防ぐ
- 重要な場面では必ず**自動テストや評価セットで品質確認**を行う

---

## まとめ

- **ハルシネーション抑止・高品質運用の基本は「低温度×top_pで絞る＋ペナルティを適度に使う」**
- **コーディング用途は温度・top_pとも低めが最適**
- **用途ごとにプリセットを作り、実際の応答で評価・微調整を繰り返す**

パラメータは「使いながらチューニングして最適解を探す」のが一番です。  
このガイドを出発点に、用途に応じたパラメータ調整をぜひ試してみてください。
