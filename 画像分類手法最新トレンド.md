# 技術レポート：ゼロショット／数ショット画像分類の主要手法

## 1. ビジョン・ランゲージモデル (VLM) によるゼロショット／数ショット分類

### 1.1 CLIP (Contrastive Language-Image Pre-Training)
- **概要**  
  [OpenAI](https://openai.com/)が提案したCLIPは、画像とテキストを同一の特徴空間にマッピングすることでゼロショット画像分類を実現するモデルです。大規模な画像とテキストのペアデータ（Web上の画像とキャプションなど）を用いて事前学習を行い、画像の埋め込みとテキストの埋め込みの「類似度」によって分類を行います。
  
- **特徴**  
  - **ゼロショット性能**：事前学習済みのCLIPに対して、新たに「分類ラベルをテキストで与えるだけ」で推論が可能（追加のファインチューニング不要）。
  - **汎用性**：特定ドメインで見られないオブジェクトでも、自然言語で表現できるなら比較的対応しやすい。
  - **限界点**：非常に細かい外観差や、Web上に十分なサンプルが無い特殊ドメインでは、適切なプロンプト設計や追加チューニングが必要になる場合がある。

- **公式リポジトリ**: [OpenAI CLIP GitHub Repository](https://github.com/openai/CLIP)

### 1.2 OpenCLIP
- **概要**  
  OpenCLIPはCLIPのアーキテクチャや学習手法をオープンソースで再実装したプロジェクトで、[LAION](https://laion.ai/)などが中心となって開発しています。CLIPと同様に大規模データで事前学習を行い、研究コミュニティや企業で活用しやすいように公開されています。
  
- **特徴**  
  - **オープンソース**：学習済みモデルや学習コードが公開されており、カスタマイズがしやすい。
  - **拡張性**：学習データセットやモデルサイズのバリエーションが豊富。

- **公式リポジトリ**: [OpenCLIP GitHub Repository](https://github.com/mlfoundations/open_clip)

### 1.3 BLIP / BLIP-2
- **概要**  
  Salesforceなどの研究グループによるビジョン・ランゲージモデル群で、「Bootstrapping Language-Image Pre-training (BLIP)」の略称です。CLIPに近い性能を持ちながら、画像キャプション生成や質問応答（VQA）など多機能化が図られています。BLIP-2は大規模言語モデル（LLM）との接続を想定したアーキテクチャを採用し、高度な画像理解や対話機能を実現しています。
  
- **特徴**  
  - **複数タスク対応**：ゼロショット画像分類だけでなく、画像のキャプション生成やVQAなど様々なタスクに展開可能。
  - **LLMとの連携**：大規模言語モデル（例：OPT、LLaMAなど）との接続により、テキスト生成能力が強化される。

- **公式リポジトリ**: 
  - [Salesforce BLIP GitHub Repository](https://github.com/salesforce/BLIP)
  - [Salesforce LAVIS GitHub Repository](https://github.com/salesforce/LAVIS)

### 1.4 PaLM-E, Kosmos-1, LLaVA, Otter 等
- **概要**  
  これらはすべて「マルチモーダル」な大規模言語モデル（LLM）として研究・開発されており、「LLM＋画像入力」の形を取ります。画像についての質問応答や説明生成などが可能です。
  
- **特徴**  
  - **柔軟なテキスト対話**：画像認識結果を踏まえて自然言語での詳しい応答や推論が可能。
  - **実用化はまだ限定的**：研究版やデモ段階のモデルが多く、安定したAPIやライブラリはこれから充実が期待されます。

- **公式リポジトリ・サイト**: 
  - [PaLM-E Official Website](https://palm-e.github.io/)
  - [Microsoft Kosmos-1 Project Page](https://www.microsoft.com/en-us/research/project/kosmos-1/)
  - [LLaVA GitHub Repository](https://github.com/haotian-liu/LLaVA)
  - [Otter GitHub Repository](https://github.com/Luodian/Otter)

---

## 2. メタラーニング／Few-Shot学習手法

### 2.1 ProtoNet (Prototypical Networks)
- **概要**  
  Few-Shot Learningにおける代表的なメタラーニング手法です。クラスごとに「プロトタイプ（代表ベクトル）」を計算し、新しいサンプルがどのプロトタイプに近いかで分類を行います。
  
- **特徴**  
  - **簡潔なメトリック学習**：クラス間の距離を測るための特徴空間を学習し、数ショットのサンプルからでもクラスごとの重心（プロトタイプ）を計算できる。
  - **拡張性**：未知のクラスが追加された場合も、数枚のサンプルから高速に対応可能。

- **公式リポジトリ**: [Prototypical Networks GitHub Repository](https://github.com/jakesnell/prototypical-networks)

### 2.2 MAML (Model-Agnostic Meta-Learning)
- **概要**  
  メタラーニング手法の代表格で、ネットワーク全体を「さまざまなタスクを素早く学習できる初期値」にするよう訓練します。新規タスク（Few-Shot）に対してはごく少ない勾配更新で高精度が得られるように設計されています。
  
- **特徴**  
  - **汎用性**：手法自体は汎用的であり、画像分類に限らずさまざまなタスクに適用可能。
  - **実装の複雑さ**：勾配の勾配を取るなど計算量が増える場合が多く、大規模データへのスケーラビリティには注意が必要。

- **公式リポジトリ**: [MAML GitHub Repository](https://github.com/cbfinn/maml)

### 2.3 Relation Network
- **概要**  
  クラス間の「類似度」を直接ネットワークが学習することで、数枚の参照画像（サポートセット）とクエリ画像を比較し、最も類似度の高いクラスを出力するFew-Shot学習の一手法です。
  
- **特徴**  
  - **ペアワイズ比較の明確化**：特徴マップ同士を比較する機構を設け、少数サンプルでの識別が可能。
  - **Meta-learningへの応用**：ProtoNetやMAML同様、少量データでの素早い学習に強み。

- **公式リポジトリ**: [Relation Network GitHub Repository](https://github.com/floodsung/LearningToCompare_FSL)

---

## 3. One-Class分類／異常検知モデル

### 3.1 AutoEncoder (AE), VAE, GAN ベース
- **概要**  
  正常画像のみを用いてネットワークに再構成を学習させ、異常画像が入力された際には再構成エラーが大きくなることを利用して異常を検知します。
  
- **特徴**  
  - **教師なし／One-Class**：異常データがほとんど無くても、正常データだけで訓練可能。
  - **異常部位の可視化**：再構成誤差マップで異常箇所の推定が可能。
  - **限界**：多種類の異常を精密に分類するには追加の工夫が必要。

- **参考リソース**: 
  - [VAE Tutorial GitHub Repository](https://github.com/lyakaap/VAE-Tutorial)
  - [PyTorch-GAN GitHub Repository](https://github.com/eriklindernoren/PyTorch-GAN)

### 3.2 Teacher-Student型 (例：STPM, PatchCore, PaDiMなど)
- **概要**  
  ResNetやVision Transformer (ViT) などの大規模事前学習モデルが抽出する特徴マップを「Teacher」として使用し、正常品での特徴分布を学習します。推論時に「Student」が生成する特徴分布とTeacherの分布の差異を測ることで異常を検知します。
  - **STPM (Student-Teacher Feature Pyramid Matching)**
  - **PatchCore**
  - **PaDiM (Patch Distribution Modeling)**
  
- **特徴**  
  - **高精度な異常検知**：大規模事前学習モデルの汎用的な特徴抽出力を活かして、正常／異常の差分をより正確に判定。
  - **ラベル不要**：正常データだけでモデルを仕上げられる（One-Class検出）。
  - **異常分類の難しさ**：種類別の分類をしたい場合は別途工夫や少量の異常データが必要になる。

- **公式リポジトリ**: 
  - [PaDiM GitHub Repository](https://github.com/xiahaifeng1995/PaDiM-Anomaly-Detection-Localization-master)
  - [PatchCore GitHub Repository](https://github.com/Alibaba-MIIL/patchcore-inspection)

---

## 4. 追加学習をほとんど必要としないプロンプトチューニング／アダプタ手法

### 4.1 LoRA (Low-Rank Adaptation)
- **概要**  
  大規模言語モデルや大規模ビジョンモデルのパラメータを固定したまま、低ランク行列による追加パラメータのみを学習する手法です。
  
- **特徴**  
  - **軽量学習**：学習対象パラメータが少ないため、学習コストが小さい。
  - **元モデルの性能活用**：大規模モデルが持っている汎用的な特徴抽出力をそのまま利用できる。

- **公式リポジトリ**: [LoRA GitHub Repository](https://github.com/amazon-research/LoRA)

### 4.2 Adapter
- **概要**  
  Transformerなどの層の間に小規模なアダプタ層を挿入し、そこだけを学習する手法です。多言語翻訳や画像タスクでも用いられ、ファインチューニングの負荷を大幅に下げます。
  
- **特徴**  
  - **モジュール化**：モデルごとではなく、アダプタを差し替える形で別タスクに対応可能。
  - **学習効率**：フルのパラメータを更新せずに済むため、ハードウェア要件が低い。

- **公式リポジトリ**: [AdapterHub GitHub Repository](https://github.com/Adapter-Hub/adapter-transformers)

### 4.3 Prompt Tuning / P-Tuning / Prefix Tuning
- **概要**  
  大規模モデルに対して、学習済みパラメータを凍結し、一部の「プロンプト」や「前置きベクトル」などだけを学習して下流タスクに適応させる手法です。主に言語モデルで発展してきましたが、ビジョン・ランゲージモデルなどでも応用されています。
  
- **特徴**  
  - **テキストプロンプトの最適化**：モデルに合わせて最適なプロンプトを自動学習。
  - **ゼロ／少量データ対応**：少量のタスクデータがあれば効果的にチューニングが可能。
  - **制約**：フルチューニングほどの自由度はなく、大きく分野が異なると対応しづらいケースもある。

- **公式リポジトリ**: [P-Tuning v2 GitHub Repository](https://github.com/THUDM/P-tuning-v2)

---

# まとめ・今後の展望

- **ビジョン・ランゲージモデル (CLIP, BLIP等)**  
  ゼロショット分類が最も容易に実現できる注目技術です。異なるクラスをテキストで定義するだけで、新たなクラス分類や異常種別の振り分けが可能となります。

- **メタラーニング (ProtoNet, MAML等)**  
  追加のデータが極少でも、新規クラスの高速学習が可能です。工場のような現場では、想定外の新しい異常クラスが発生した場合に少量のサンプルで対応可能な点が強みです。

- **One-Class分類 (AE, Teacher-Student等)**  
  異常データがほぼ無い場合や、未知異常を検出したい場合に有効です。ここから「分類」の方向に拡張するには追加のラベルデータや工夫が必要です。

- **プロンプトチューニング／アダプタ手法 (LoRA, Adapter, P-Tuning等)**  
  元の大規模モデルを改変せずにタスク適応できるため、学習コストが小さく実用的です。少量データでの微調整にも向いています。

今後は、画像とテキストだけでなくセンサーデータや時系列データなどを含む**マルチモーダル大規模モデル**が研究され、工場などの産業用途での応用がさらに拡大すると考えられます。また、エッジ推論環境への最適化や、未知異常対応（オープンセット認識）を高精度化するための研究も進展が期待されます。

---

以上が「ゼロショット／数ショットで高精度な画像分類を行う」主要な技術についての概要レポートです。各モデル・手法はそれぞれ異なる得意分野や前提条件を持つため、実際の工場適用では「異常ラベルの定義」「データ収集の容易さ」「ハードウェアリソース」などを踏まえて選定することが重要です。

各技術の詳細や実装については、以下の公式リポジトリや情報源をご参照ください。これらのリソースを活用して、各技術の理解や実装にお役立てください。

---

## 参考リンク

### 1. ビジョン・ランゲージモデル (VLM) によるゼロショット／数ショット分類
- **CLIP (Contrastive Language-Image Pre-Training)**
  - [OpenAI CLIP GitHub Repository](https://github.com/openai/CLIP)
  
- **OpenCLIP**
  - [OpenCLIP GitHub Repository](https://github.com/mlfoundations/open_clip)
  
- **BLIP / BLIP-2**
  - [Salesforce BLIP GitHub Repository](https://github.com/salesforce/BLIP)
  - [Salesforce LAVIS GitHub Repository](https://github.com/salesforce/LAVIS)
  
- **PaLM-E, Kosmos-1, LLaVA, Otter 等**
  - [PaLM-E Official Website](https://palm-e.github.io/)
  - [Microsoft Kosmos-1 Project Page](https://www.microsoft.com/en-us/research/project/kosmos-1/)
  - [LLaVA GitHub Repository](https://github.com/haotian-liu/LLaVA)
  - [Otter GitHub Repository](https://github.com/Luodian/Otter)

### 2. メタラーニング／Few-Shot学習手法
- **ProtoNet (Prototypical Networks)**
  - [Prototypical Networks GitHub Repository](https://github.com/jakesnell/prototypical-networks)
  
- **MAML (Model-Agnostic Meta-Learning)**
  - [MAML GitHub Repository](https://github.com/cbfinn/maml)
  
- **Relation Network**
  - [Relation Network GitHub Repository](https://github.com/floodsung/LearningToCompare_FSL)

### 3. One-Class分類／異常検知モデル
- **AutoEncoder (AE), VAE, GAN ベース**
  - [VAE Tutorial GitHub Repository](https://github.com/lyakaap/VAE-Tutorial)
  - [PyTorch-GAN GitHub Repository](https://github.com/eriklindernoren/PyTorch-GAN)
  
- **Teacher-Student型 (STPM, PatchCore, PaDiMなど)**
  - [PaDiM GitHub Repository](https://github.com/xiahaifeng1995/PaDiM-Anomaly-Detection-Localization-master)
  - [PatchCore GitHub Repository](https://github.com/Alibaba-MIIL/patchcore-inspection)

### 4. 追加学習をほとんど必要としないプロンプトチューニング／アダプタ手法
- **LoRA (Low-Rank Adaptation)**
  - [LoRA GitHub Repository](https://github.com/amazon-research/LoRA)
  
- **Adapter**
  - [AdapterHub GitHub Repository](https://github.com/Adapter-Hub/adapter-transformers)
  
- **Prompt Tuning / P-Tuning / Prefix Tuning**
  - [P-Tuning v2 GitHub Repository](https://github.com/THUDM/P-tuning-v2)

---

これらのリポジトリには、実装コードや詳細なドキュメンテーションが含まれています。各技術の理解や実装にぜひご活用ください。